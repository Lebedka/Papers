\section{Simply-typed lambda calculus with continuations} \label{tex:math_prelim}


\cite{Church:1940:A-formulation-of-the-simple-theory-of-types},~\cite{Barendregt:1981:The-Lambda-Calculus:-Its-Syntax-and-Semantics},~\cite{Barendregt:1992:Lambda-Calculi-with-Types} and~\cite{HindleySeldin:2008:Lambda-Calculus-and-Combinators-an-Introduction}

%In this section the basic definitions and theorems of type-free (2.1) and
%simply-typed (2.2) lambda calculus, based on [1], [2] and [10], are presented.
%The last subsection overviews the basic principles of the continuation-passing
%technique and illustrates them on simple programming examples

\subsection{Simply-typed lambda calculus} \label{sec:STLC}

\begin{definition}[$\lambda$-terms] The set of \textbf{$\lambda$-terms} $\Lambda$ constructed from an enumerable set of variables $V = \{ v, v_1 ,v_2, \dots\}$ is defined inductively as follows:
\begin{center}
$
\begin{array}{rcll}
x \in V & \Longrightarrow & x \in \Lambda &\\
M,N \in \Lambda &  \Longrightarrow & (MN) \in \Lambda & \text{(\textbf{application})}\\ 
 x \in V, M \in \Lambda&  \Longrightarrow  & (\lambda x.M) \in \Lambda & \text{(\textbf{abstraction})}
\end{array} 
$
\end{center}
\end{definition}

In the term $ (\lambda x.M)$, called abstraction, the variable $x$ is the \textbf{argument} of the function and $M$ is the \textbf{body} of the function. %The variable $x$ is \textbf{bound} by $\lambda$ in  $ (\lambda x.M)$.

\begin{remark}[Parenthesis conventions] \label{rem:parcon} \ \\
\vspace{-15pt}
\begin{itemize}
\item application is left-associative
$$MN_1 N_2 \dots N_n \seq (\dots ( (MN_1) N_2 ) \dots N_n)$$
\item  a sequence of $\lambda$-abstractions $\lambda x_1. (\lambda x_2. ( \dots (\lambda x_n. M) )  ) $ is abbreviated as \\ $\lambda x_1 x_2 \dots x_n.M$
$$\lambda x_1 x_2 \dots x_n.M \seq \lambda x_1. (\lambda x_2. ( \dots (\lambda x_n. M) )  )  $$
\item parentheses surrounding the body of an abstraction can be dropped
$$\lambda x_1 x_2 \dots x_n.(M) \seq \lambda x_1 x_2 \dots x_n.M$$
\item outermost parentheses can be dropped 
$$(M) \seq M$$
\end{itemize}
\end{remark}
%application has a higher precedence than abstraction. 
Note that according to the conventions on parentheses, term $\lambda x. MN$ is a more concise way of writing $\lambda x. (MN)$ and is not equivalent to $(\lambda x. M)N$. 

\begin{definition}[Free and bound variables] A variable $x$ is \textbf{free} in a $\lambda$-term $M$ if $x$ is not in the scope of $\lambda x$. If $x$ is in the scope of $\lambda x$, it is \textbf{bound}.
\end{definition}

\begin{definition}[Closed $\lambda$-terms] \ 
\begin{enumerate}
\item The set of \textbf{free variables} of $M$, $FV(M)$ is defined inductively as follows:
\begin{align*}
 FV(x)  & = \{ x \} \\
 FV(\lambda x.M)  & = FV(M) - \{ x \} \\
 FV(MN)  & = FV(M) \cup FV(N)
\end{align*}
\item M is \textbf{closed} or a \textbf{combinator}, if $FV(M) = \emptyset$

\end{enumerate}
\end{definition}

If an equation $M=N$ is provable in the lambda calculus, the provability is denoted by $\lambda \vdash M = N$
or sometimes just by $M=N$.

\begin{definition}[Axioms and rules] For all $M,N, L,Z \in \Lambda$ the following axioms and rules hold:
\begin{prooftree}
\AXC{} \RightLabel{$\beta$-conversion}
\UIC{$(\lambda x.M)N = M[x:=N]$}
\end{prooftree}

\begin{prooftree}
\AXC{}
\UIC{$M = M$}
\end{prooftree}

\begin{prooftree}
\AXC{$M = N$}
\UIC{$N = M$}
\end{prooftree}

\begin{prooftree}
\AXC{$M=N$}
\AXC{$N=L$}
\BIC{$M=L$}
\end{prooftree}

\begin{prooftree}
\AXC{$M=N$}
\UIC{$MZ=NZ$}
\end{prooftree}

\begin{prooftree}
\AXC{$M=N$}
\UIC{$ZM=ZN$}
\end{prooftree}

\begin{prooftree}
\AXC{$M=N$} \RightLabel{rule $\xi$}
\UIC{$\lambda x.M=\lambda x.N$}
\end{prooftree}

\end{definition}


\begin{definition}[Substitution] The result of \textbf{substitution} of $N$ for the free occurences of $x$ in $M$, i.e. $M[x:=N]$, is defined inductively on the structure of $M$ as follows:
\begin{align*}
 x[x:=N] \defeq  \ & N \\
 y[x:=N] \defeq  \ &  y \ \ \text{provided} \ x \nseq y \\
 (\lambda y.M_1)[x:=N] \defeq   \ & \lambda y. (M_1 [x:=N]) \\
 (M_1 M_2)[x:=N] \defeq  \  & (M_1[x:=N])(M_2[x:=N]) \\
 (\lambda x.M_1)[x:=N]  \defeq \ & \lambda x.M_1
\end{align*}

\end{definition}

\begin{lemma}[Substitution lemma] If  $x \nseq y$ and $x \notin FV(L)$, then
\begin{align*}
 M[x:=N][y:=L] \seq M[y:=L][x:=N[y:=L]]
\end{align*}
\end{lemma}
\begin{proof} The proof is by induction on the structure of $M$.
\end{proof}


When performing a substitution $M[x:=N]$, it is necessary to rename those bound variables in $M$ that are free in N. Otherwise, the substitution 
may lead to a false result. For example, without renaming the bound variable $x$ in $\lambda x.xy$, the substitution  $(\lambda x.xy)[y:=x]$ leads to the term $\lambda x.xx$ that acts differently from the desired term, because the free variable $x$ became bound. However, changing $x$ to $z$, for example, before making the substitution, leads to the desired term $\lambda z.zx$. 

\begin{definition}[$\alpha$-conversion] A \textbf{change of bound variable} $x$ in $M$, or an \textbf{$\alpha$-conversion} in $M$, is the replacement of an occurrence of $\lambda x.N$ in $M$ by $\lambda y.(N[x:=y])$, where $y$ does not occur in $N$.
\end{definition}

\begin{definition}[$\alpha$-congruency] $M$ and $N$ are \textbf{$\alpha$-congruent}, denoted $M \congr N$, if one can result from the other by a finite series of changes of bound variables.
\end{definition}

It is natural to identify the terms that are $\alpha$-congruent, as they represent the same processes. Moreover, the same processes can be represented by different terms. For example, $\lambda x.Mx$ and $M$ both lead to $MN$ when applied to $N$. Hence, the following rule can be introduced:
\begin{definition}[Extensionality] \textbf{Extensionality} is the following derivation rule, provided $x \notin FV(MN)$:
\begin{prooftree}
\AXC{$Mx = Nx$}
\UIC{$M = N$}
\end{prooftree}
\end{definition}
The extensionality rule allows to prove $\lambda x. Mx = M$. Alternatively,  $\lambda x. Mx = M$ can be considered to be an axiom:
\begin{definition}[$\eta$-conversion] Let $x \notin FV(M)$. Then
\begin{prooftree}
\AXC{} \RightLabel{$\eta$-conversion}
\UIC{$\lambda x. Mx = M$}
\end{prooftree}
\end{definition}

\begin{definition}[$\beta$-normal form]
\begin{enumerate}
\item $M$ is a \textbf{$\beta$-normal form}, if $M$ has no subterm of the form $(\lambda x.L)K$
\item $M$ \textbf{has a $\beta$-normal form}, if there exists an $N$ such that $N$ is a $\beta$-normal form and $N = M$.
\end{enumerate}
\end{definition}

When $M$ is a $\beta$-normal form, it is often said that $M$ is in normal form.


A notion of reduction on $\Lambda$ is a binary relation on $\Lambda$. The classical notion of reduction $\beta$ is defined as follows:
\begin{definition} $\beta = \{ ( (\lambda x. M)N , M[x:=N] ) | M, N \in \Lambda  \} $
\end{definition}

\begin{definition}[$\beta$-redex, $\beta$-contractum] 
A \textbf{$\beta$-redex} is a term $M$ such that $(M,N) \in \beta$ for some term $N$. In this case $N$ is called \textbf{$\beta$-contractum} of $M$.
\end{definition}

\begin{definition} The notion of reduction $\beta$ induces the following binary relations:
\begin{align*}
\bconv \  & \textbf{one-step } \beta \textbf{-reduction} \\
\bred \  &  \beta \textbf{-reduction} \\
=_{\beta} \  & \beta \textbf{-equality} \text{ (also called } \beta \textbf{-convertibility}\text{)} 
\end{align*}
These relations are inductively defined as follows:
\begin{center}
$
\begin{array}{rcl}
(M,N) \in \beta & \Longrightarrow & M \bconv N \\
M \bconv N &  \Longrightarrow & ZM \bconv ZN \\ 
M \bconv N &  \Longrightarrow & MZ \bconv NZ \\ 
M \bconv N & \Longrightarrow & \lambda x.M \bconv \lambda x.N \\
& & \\
M \bconv N &  \Longrightarrow & M \bred N \\ 
M \bred M & \\ 
M \bred N, N \bred Z & \Longrightarrow & M \bred Z \\
&& \\
M \bred N &  \Longrightarrow & M =_{\beta} N \\ 
M =_{\beta} N & \Longrightarrow & N =_{\beta} M\\ 
M =_{\beta} N, N =_{\beta} Z & \Longrightarrow & M =_{\beta} Z 
\end{array} 
$
\end{center}


\end{definition}

The notions of $\beta$-redex and $\beta$-equality allow to give an alternative, more formal, definition of $\beta$-normal form:
\begin{definition}[$\beta$-normal form]  
\begin{enumerate}
\item A term $N$ is called a $\beta$-normal form, if $N$ does not contain (as subterm) any $\beta$-redex.
\item A term $N$ is a $\beta$-normal form of $M$, if $N$ is a $\beta$-normal form and $M =_{\beta} N$.
\end{enumerate}
\end{definition}


The notion of $\beta$-reduction is very important, because it characterizes provability in $\lambda$ and it is Church-Rosser:

\begin{proposition} $M =_{\beta} N$ iff $\lambda \vdash M = N$
\end{proposition}
\begin{proof} %See~\cite[p.59]{Barendregt:1981:The-Lambda-Calculus:-Its-Syntax-and-Semantics}.
\begin{itemize}
\item Assume $\lambda \vdash M = N$. Use the induction on the length of the proof of $M=N$.
\item Assume $M =_{\beta} N$. Show by induction on the definition of the relations involved that
\end{itemize}
\end{proof}


\begin{theorem}[Church-Rosser theorem for $\bred$] If $L \bred M$ and $L \bred N$, then there exists a term $Z$ such that $M \bred Z$ and $N \bred Z$.
\end{theorem}
\begin{proof} See~\cite[p.62]{Barendregt:1981:The-Lambda-Calculus:-Its-Syntax-and-Semantics} or~\cite[p.289]{HindleySeldin:2008:Lambda-Calculus-and-Combinators-an-Introduction}.
\end{proof}
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.3\textwidth]{images/Diamond.pdf}
      \caption{Diamond property.} \label{fig:diamond}
\end{figure}

The Church-Rosser theorem says that for two $\beta$-convertible terms, there is a term to which they both $\beta$-reduce, as illustrated in Figure~\ref{fig:diamond}. The property described in the theorem, that if a term can be reduced to two different terms, then these two terms can be further reduced to one term, is called the \textbf{diamond property} or \textbf{confluence}. The theorem states that $\beta$-reduction is confluent.

Lambda terms can be assigned expressions, called ``types'', to denote their intended input and output sets. There exists two typing paradigms: 
\`{a} la Curry, sometimes called \textbf{implicit}, and \`{a} la Church, sometimes called \textbf{explicit}. Below the basics of Curry-style approach are overviewed, as this style is used subsequently in continuation-based dynamic logic developed in this paper.


\begin{definition}[Simple types] Given a set $A$ of \textbf{atomic types}, the set of \textbf{types} $T$ is inductively defined as follows:
\begin{center}
$
\begin{array}{rcll}
\alpha \in A & \Longrightarrow & \alpha \in T &\\
\alpha, \beta \in A &  \Longrightarrow & (\alpha \rightarrow \beta) \in T & \text{(\textbf{function types})}
\end{array} 
$
\end{center}
\end{definition}
An atomic type is intended to denote some particular set. A function type $(\alpha \rightarrow \beta)$ is intended to denote some set of functions from $\alpha$ to $\beta$, i.e. the functions that take as the argument a member of the set denoted by $\alpha$ and return as an output a member of the set denoted by $\beta$.


\begin{remark}[Parenthesis convention] A complex functional type $(\alpha_1 \rightarrow (\alpha_2 \rightarrow \dots \rightarrow (\alpha_{n-1} \rightarrow \alpha_n)  \dots ))$ is abbreviated as $\alpha_1 \rightarrow \alpha_2 \rightarrow \dots \rightarrow \alpha_n$ (i.e. parentheses are associated to the right):
\begin{align*}
(\alpha_1 \rightarrow (\alpha_2 \rightarrow \dots \rightarrow (\alpha_{n-1} \rightarrow \alpha_n)  \dots )) & \seq \alpha_1 \rightarrow \alpha_2 \rightarrow \dots \rightarrow \alpha_n
\end{align*}
\end{remark}


\begin{definition}[$\lambda\!\rightarrow$-Curry]
\begin{enumerate}
\item A \textbf{statement} is of the form $M:\sigma$ with $M \in \Lambda$ and $\sigma \in T$. The type $\sigma$ is the \textbf{predicate} and the term $M$ is the \textbf{subject} of the statement.
\item A \textbf{declaration} is a statement with a variable as a subject.
\item A \textbf{basis} is a set of declarations with distinct variables as subjects.
\end{enumerate}
\end{definition}


\begin{definition}[Derivation rules in $\lambda\!\rightarrow$-Curry] A statement $M:\sigma$ is \textbf{derivable} from a basis $\Gamma$, denoted $\Gamma \vdash_{\lambda\rightarrow \text{-Curry}} M: \sigma$ , $\Gamma \vdash_{\lambda\rightarrow} M: \sigma$ or simply $\Gamma \vdash M: \sigma$, if $\Gamma \vdash M: \sigma$ can be produced by the following rules:
 
\begin{prooftree}
\AXC{} \RightLabel{axiom}
\UIC{$\Gamma, x: \alpha \vdash x: \alpha $}
\end{prooftree} 
 
 \begin{prooftree}
\AXC{$\Gamma \vdash M: \alpha \rightarrow \beta$}
\AXC{$\Gamma \vdash N: \alpha$} \RightLabel{app}
\BIC{$\Gamma \vdash MN: \beta$}
\end{prooftree}

\begin{prooftree}
\AXC{$\Gamma, x: \alpha \vdash M:\beta$} \RightLabel{abs}
\UIC{$\Gamma \vdash \lambda x.M: \alpha \rightarrow \beta$}
\end{prooftree}

\end{definition}


\begin{lemma}[Substitution lemma for $\lambda\!\rightarrow$-Curry] \label{lem:substitution-Curry} \
\begin{enumerate}
\item If $\Gamma \vdash M:\sigma$, then $\Gamma[\alpha :=\tau] \vdash M:\sigma[\alpha :=\tau]$.
\item Suppose $\Gamma, x: \sigma \vdash M: \tau$ and $\Gamma \vdash N: \sigma$. Then $\Gamma \vdash M[x:=N]: \tau$.
\end{enumerate}
\end{lemma}
\begin{proof} 
\begin{enumerate}
\item The proof is by induction on the derivation of $M:\sigma$.
\item The proof is by induction on the generation of $\Gamma, x: \sigma \vdash M:\tau$
\end{enumerate}
\end{proof}

The following theorem states that the set of terms having a certain type is closed under reduction:
\begin{theorem}[Subject reduction theorem for $\lambda\!\rightarrow$-Curry] Suppose $M \bred N$. Then 
\begin{center}
$
\begin{array}{rcl}
\Gamma \vdash M: \sigma &\Longrightarrow & \Gamma \vdash N: \sigma
\end{array}
$
\end{center}
\end{theorem}
\begin{proof} See~\cite[p.41]{Barendregt:1992:Lambda-Calculi-with-Types}.
\end{proof}

\subsection{Continuation}

Montague's program requires the meaning of an expression to be computed compositionally from meanings of its lexical constituents. Dynamics of natural language makes, however, this task non-trivial. A similar kind of problem occurred in the mathematical semantics of programming languages, particularly in formalizing full jumps (``goto'' statements) in a compositional way. To solve this problem, the method of continuations was introduced in~\cite{StracheyWadsworth:1974:Continuations:-A-Mathematical-Semantics-for-Handling-Full-Jumps} to extend the mathematical semantics of programming languages~\cite{ScottStrachey:1971:Toward-a-Mathematical-Semantics-for-Computer-Languages} with a general formalized notion of control of full jumps. According to this method, if the evaluation of a program is in a state $s$, and the following command is $c$, continuation represents the state transition which would be produced up to the end of the program (i.e. the rest of the computation) after performing the state transformation specified by $c$. Every function of a program written in continuation-passing style is given as an argument to the continuation of the program with respect to this function. 


A program can be transformed from direct style to continuation-passing style (CPS).
Plotkin~\cite{Plotkin:1975:Call-by-Name-Call-by-Value-and-the-lambda-Calculus} introduced a possible way of CPS-transforming terms of typed lambda calculus. Definition~\ref{def:CPS-transformation} shows Plotkin's call-by-value transformation: 
%Moreover, they showed that for typed $\lambda$-calculus the original terms can be recovered from corresponding CPS-terms.
%~\cite{MeyerWand:1985:Continuation-Semantics-in-Typed-Lambda-Calculi-Summary}
\begin{definition}[CPS-transformation]\label{def:CPS-transformation} Let $o$ be a distinguished type. For each term $t$ of type $\rho$, it is possible to construct its CPS-transformation $\overline{t}$ of type $\overline{\rho}$ in the following way
%
\begin{align*}
\overline{x} & = \lambda \phi^{\rho \rightarrow o}. \phi x^{\rho}  \\
\overline{\lambda x^{\alpha}.N^{\beta}} & = \lambda \phi^{(\alpha \rightarrow \beta)' \rightarrow o}. \phi  (\lambda x^{\alpha'}. \overline{N}^{\overline{\beta \rightarrow o}}) \\
\overline{M^{\alpha \rightarrow \beta}N^\alpha} & = \lambda \phi^{\beta' \rightarrow o}. \overline{M}^{\overline{\alpha \rightarrow \beta} }(\lambda m^{(\alpha \rightarrow \beta)'}. \overline{N}^{\overline{\alpha}}(\lambda n^{\alpha'}.mn \phi)) 
\end{align*}
%
where $\phi$ of type $(\rho' \rightarrow o)$ is a \textbf{continuation} of $t$. Each type  $\overline{\rho}$ is defined as $(\rho' \rightarrow o) \rightarrow o$, where $\rho'$ is as follows
%
\begin{align*}
\rho' = \left\{
\begin{array}{rl} 
\rho & \text{if } \rho \text{ is basic}\\
{\alpha'} \rightarrow ({\beta}' \rightarrow o) \rightarrow o & \text{if } \rho = \alpha \rightarrow \beta \end{array} \right.
\end{align*}
\end{definition}

For a better understanding of CPS-transformation, it is important to keep the type assignments in mind. That is why terms in Definition~\ref{def:CPS-transformation} are presented together with their types as superscripts. Equations~\eqref{eqs:cps} repeat equations in Definition~\ref{def:CPS-transformation} with types omitted for better readability:
%
\begin{subequations}
\begin{align}
\overline{x} & = \lambda \phi. \phi x \label{eq:var}  \\
\overline{\lambda x.N} & = \lambda \phi. \phi (\lambda x. \overline{N}) \label{eq:abst}\\
\overline{MN} & = \lambda \phi. \overline{M}(\lambda m. \overline{N}(\lambda n.mn \phi)) \label{eq:app}
\end{align} \label{eqs:cps}
\end{subequations}

It is possible to make a CPS-transformation of an application in a way that the argument is evaluated before the function. Equation \eqref{eq:app-nws} shows the corresponding transformation rule:
%
\begin{align}
\overline{MN} & = \lambda \phi. \overline{N}(\lambda n. \overline{M}(\lambda m.mn \phi)) \label{eq:app-nws}
\end{align}

The transformation presented above imposes \textbf{call-by-value} evaluation strategy in the resulting term. According to the call-by-value strategy, the argument expression is evaluated before being passed to the function.\footnote{Call-by-value is usually contrasted with call-by-name evaluation strategy. According to call-by-name, the argument of a function is not evaluated before the evaluation of the function.} 


Continuation-like approaches can already be found in earlier work on formal compositional semantics of natural language. Indeed, Montague's~\cite{Montague:1973:The-Proper-Treatment-of-Quantification-in-Ordinary-English} technique of type-raising can be seen as using continuation technique for quantifiers to take scope over complete sentences. In this type-raised setting, scope ambiguities (subject wide scope versus object wide scope) correspond to the change of evaluation order of the arguments. This is one of the features that continuation-style allows. To see the similarity between the type-raising and CPS-transformation, compare two possible interpretations~\eqref{eq:MS:looooves-a} and~\eqref{eq:MS:looooves-b} that account for the scope ambiguity of a transitive verb with respectively equations~\eqref{eq:app} and~\eqref{eq:app-nws} that impose different evaluation order of the arguments.
%
\begin{subequations}
\begin{align}
\I{loves}_{sws} = \ & \lambda OS. S (\lambda x. O (\lambda y. \textbf{love} x y) ) \label{eq:MS:looooves-a} \\
\I{loves}_{ows} = \ & \lambda OS. O (\lambda y. S (\lambda x. \textbf{love} x y) ) \label{eq:MS:looooves-b}
\end{align}
\label{eq:MS:looooves}
\end{subequations}
%
%\begin{subequations}
%\begin{align}
%\overline{MN} & = \lambda \phi. \overline{M}(\lambda m. \overline{N}(\lambda n.mn \phi)) \\
%\overline{MN} & = \lambda \phi. \overline{N}(\lambda n. \overline{M}(\lambda m.mn \phi)) 
%\end{align}
%\label{eq:apppp}
%\end{subequations}
More recent research confirms that continuation-passing technique is very useful for formalizing natural language (discourse) semantics. For example Barker~\cite{Barker:2002:Continuations-and-the-Nature-of-Quantification} investigates in more details how continuized $\lambda$-terms expressing natural language meanings provide a way of dealing with phenomena related to quantification, such as scope displacement and scope ambiguity, and give a unified account of quantificational and non-quantificational noun phrases. Additionaly, Barker~\cite{Barker:2004:Continuations-in-Natural-Language} shows that CPS can be used to deal with focus, coordination and misplaced quantifiers.\footnote{Other interesting continuation-based analyses of different natural language phenomena include~\cite{Shan:2002:A-continuation-semantics-of-interrogatives-that-accounts-for-Bakers-ambiguity,Shan:2004:Delimited-continuations-in-natural-language,BarkerShan:2008:Donkey-Anaphora-is-In-Scope-Binding}.}

Definition~\ref{def:CPS-transformation} transforms a program into an equivalent CPS program. The advantage of a program written in continuation passing style is that it can be expanded with unusual expressions, e.g. non-local transfers of control, in order to manage the execution of the program. For example, one of the possible control expressions of a function can be to  discard all the future of the computation (i.e. its continuation) and return the error as a result of the whole program, in the case an error happens within this function. Examples~\ref{ex:divbyzero}--\ref{ex:CPScontrolfinal} show how it can be done in the case of division by zero.
%

Example~\ref{ex:divbyzero} considers a $\lambda$-term $t$ equal to $(\lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y)) $ that computes $\sqrt{ \dfrac{x}{y}}$. During the evaluation of $t$, if the execution of $\mathsf{div}$ leads to an error, the error message is passed to the function $\mathsf{sqrt}$ as the argument. Assuming that $\mathsf{sqrt}$ is defined simply as a square root of its argument, this leads to $\mathsf{sqrt}$ being applied to a value for which it is not defined. 
\begin{example} \label{ex:divbyzero} $t  = \lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y) $
\begin{align}
%t & = \lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y) \notag \\ % \label{eq:tstat}
%\end{align}
%
%
%\begin{align}
t(9)(0) & =  (\lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y))(9)(0)  \notag \\
& \bconv   (\lambda y. \mathsf{sqrt} (\mathsf{div} \ 9 \ y) ) (0)  \notag \\
& \bconv \mathsf{sqrt} (\mathsf{div} \ 9 \ 0)  \notag \\
& = \mathsf{sqrt} (\mathtt{error} ) \label{sqrterrow}\\
& =  \ ??? \notag
\end{align} \qex
\end{example}

This situation could be handled in the original direct program by adding at the beginning of $\mathsf{sqrt}$ a conditional expression that checks whether the argument is an $\mathtt{error}$ (and returning an  $\mathtt{error}$ in this case) or a number (and calculating the square root of the number in this case). However, this means that, following this style, such a condition would have to be added to all other possible functions of the program. In contrast, the CPS technique allows to provide control to the division function itself in a way that it terminates the whole program when an error occurs during its execution.

Equation shows the result $\overline{t}$ of CPS-transformation of $t$ according to Definition~\ref{def:CPS-transformation}.
The transformations of functions $\mathsf{sqrt} $ and $\mathsf{div} $, shown below, were used in intermediary steps of the transformation:
\todo{How were these transformations obtained?}
\begin{subequations}
\begin{align}
\overline{\mathsf{sqrt}} & = \lambda \phi . \phi ( \lambda x \phi'  . \phi'(  \mathsf{sqrt}  x))  \label{sqrt-3} \\
\overline{\mathsf{div}} & = \lambda \phi . \phi  (  \lambda x \phi' . \phi' ( \lambda y \phi''. \phi '' ( \mathsf{div} \ x \ y))) \label{div-3}  \\
\overline{\lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y)}  & = \lambda \phi. \phi ( \lambda x \phi'. \phi' ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ x\ y )))) \label{eq:exdivbyzero} 
\end{align} 
\end{subequations}


%\overline{t} & =  \lambda \phi. \phi (\lambda x \phi'. \phi' ( \lambda y \phi''. \phi''(\mathsf{sqrt} (\mathsf{div} \ x \ y) ))) \label{eq:exdivbyzeroCPS}

Since normalized term $\overline{t}$ is obtained from $t$ only by applying definitions of CPS-transformation, it is equivalent to $t$  and behaves analogously when an error happens inside the division function. To demonstrate this, $\overline{t}$ is given in Example~\ref{ex:divbyzeroCPStransformed} the same (continuized) arguments 9 and 0 as $t$ in Example~\ref{ex:divbyzero}. The fact that the result is equally undesirable can be seen by comparing Equations~\eqref{sqrterrow} and~\eqref{sqrterrowCPS}:

\begin{example}
\begin{align}
& \lambda \phi'''. \overline{t} (\lambda \phi''''. \phi'''' 9 (\lambda \phi'''''. \phi''''' 0 \phi''')) \notag \\
 = \ & \lambda \phi'''. (\lambda \phi. \phi ( \lambda x \phi'. \phi' ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ x\ y ))))) (\lambda \phi''''. \phi'''' 9 (\lambda \phi'''''. \phi''''' 0 \phi''')) \notag \\
  \bconv  \ & \lambda \phi'''.  (\lambda \phi''''. \phi'''' 9 (\lambda \phi'''''. \phi''''' 0 \phi''')) ( \lambda x \phi'. \phi' ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ x\ y ))))\notag \\  
    \bconv  \ & \lambda \phi'''.  ( \lambda x \phi'. \phi' ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ x\ y )))) 9 (\lambda \phi'''''. \phi''''' 0 \phi''')\notag \\
     \bred  \ & \lambda \phi'''.   (\lambda \phi'''''. \phi''''' 0 \phi''') ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ 9\ y ))) \notag \\ 
 \bconv  \ & \lambda \phi'''.    ( \lambda y \phi ''. \phi''  (\mathsf{sqrt} ( \mathsf{div} \ 9\ y )))  0 \phi'''\notag \\
\bred \ & \lambda \phi'''. \phi''' \mathsf{sqrt} (\mathsf{div} \ 9 \ 0)  \notag \\
 =  \ & \lambda \phi'''. \phi''' (\mathsf{sqrt} (\mathtt{error} )) \label{sqrterrowCPS}\\
 =   \ & ??? \notag
\end{align} \qex \label{ex:divbyzeroCPStransformed}
\end{example}

However, an advantage of the CPS-written program~\eqref{eq:exdivbyzero} is that it can be extended with an unusual control due to the fact that it, as well as its functions, have continuations as arguments. Particularly, division can be refined in a way so that when the divisor is zero, it disregards the continuation and immediately returns an error message as a result of the whole program; and otherwise provides the result of the division to its continuation. 
Thus, one can modify $\overline{\mathsf{div}}$ given in~\eqref{div-3} by adding a control on whether $y$ is equal to zero or not, as shown in~\eqref{div-4}:
%
\begin{align}
\overline{\mathsf{div}} = \ & \lambda \phi . \phi ( \lambda x \phi'. \phi' ( \lambda y .  \mathsf{if} \ (y =0)  \ \mathsf{then} \ \mathtt{error}  \ \mathsf{else}  \  (\lambda \phi''. \phi'' (\mathsf{div} \ x \ y) )) ) \label{div-4}
\end{align} 

With Equation~\eqref{div-4} a CPS program~\eqref{eq:exdivbyzeroCPScontrol} that has a special treatment for division by zero can be obtained:
%
\begin{example}
%\begin{footnotesize}
\begin{align}
 \overline{\lambda xy. \mathsf{sqrt} (\mathsf{div} \ x \ y)} 
  = \ & \lambda \phi. \phi ( \lambda x. ( \lambda \phi'. \phi' ( \lambda y. ( \lambda \phi''.    \mathsf{if} \ (y = 0)  \ \mathsf{then} \ \mathtt{error}  \notag \\
  & \phantom{\lambda \phi. \phi   }
   \mathsf{else}  \  (\lambda \phi'''. \phi''' (\mathsf{div} \ x \ y) )  (\lambda n.  \phi''(  \mathsf{sqrt}  n)) ) ))) \label{eq:exdivbyzeroCPScontrol} 
\end{align} \qex
%\end{footnotesize}
\end{example}

%
Term~\eqref{eq:exdivbyzeroCPScontrol}, abbreviated below as $\overline{t}^{control}$, computes a square root of a result of a division, as programs $t$ and $\overline{t}$ do. However, since $\overline{t}^{control}$ has the control over division by zero it, unlike $t$ and $\overline{t}$, terminates with an error when the divisor is equal to zero:
%
\begin{example} \label{ex:CPScontrolfinal}
%\begin{footnotesize}
\begin{align}
& \lambda \phi. \overline{t}^{control} (\lambda \phi'. \phi' 9 (\lambda \phi''. \phi'' 0 \phi)) \notag \\
%= \ & \lambda \phi. (\lambda \phi. \phi ( \lambda x. ( \lambda \phi'. \phi' ( \lambda y. ( \lambda \phi''.    \mathsf{if} \ (y = 0)  \ \mathsf{then} \ \mathtt{error}  \notag \\
%& \phantom{\lambda \phi. (\lambda \phi. \phi ( \lambda x. ( \lambda \phi'. \phi' ( \lambda y. ( \lambda \phi''.} 
% \mathsf{else}  \  (\lambda \phi'''. \phi''' (\mathsf{div} \ x \ y) )  (\lambda n.  \phi''(  \mathsf{sqrt}  n)) ) )))) \notag \\
% & \phantom{\lambda \phi.} (\lambda \phi'. \phi' 9 (\lambda \phi''. \phi'' 0 \phi)) \notag \\
  \bred \ & \lambda \phi.   ( \lambda y. ( \lambda \phi''.    \mathsf{if} \ (y = 0)  \ \mathsf{then} \ \mathtt{error} \ \mathsf{else}  \  (\lambda \phi'''. \phi''' (\mathsf{div} \ 9 \ y) )  (\lambda n.  \phi''(  \mathsf{sqrt}  n)) ) ) 0 \phi \notag \\
    \bred \ & \lambda \phi. \mathsf{if} \ (0 = 0)  \ \mathsf{then} \ \mathtt{error} \ \mathsf{else}  \  (\lambda \phi'''. \phi''' (\mathsf{div} \ 9 \ 0) )  (\lambda n.  \phi(  \mathsf{sqrt}  n))  \notag \\
=  \ & \ \mathtt{error} \notag %\label{errormsg}
\end{align} \qex
%\end{footnotesize}
\end{example}

As mentioned above, the method of continuation was introduced to give compositional semantics to full jumps in programming languages. Next example illustrates on the example of a simple language that continuation-based interpretation of $\abort$ operation leads to desired evaluation of a program, while a direct interpretation does not.

\begin{example}
Consider a small programming language $L_1$ consisting of variables from set $\vvar$, expressions from set $\expr$, symbols $:=$ and $;$. The language has the following simple grammar, where $S$ stands for a statement:
\begin{align}
S  \defeq \ & \vvar := \expr \ | \notag \\
&  S;S \notag
\end{align}
Let $\state$ be a function mapping variables to natural numbers:
\begin{align}
\state = \ \vvar \rightarrow \mathbb{N} \notag
\end{align}
The statements $S$ in $L_1$ are interpreted with the function $I$ that maps expressions to natural numbers and statements to transformation on states:
\begin{align}
I_{\expr}: \ & \expr \rightarrow \mathbb{N} \notag \\
I_{S}: \ & S \rightarrow (\state \rightarrow \state) \notag 
\end{align}
Then, compositional semantics of this language can be defined as below, where $\xi$ is a state:
\begin{align}
I_{S}(x:=e)\xi = \ & \xi[x := I_{\expr}(e)] \notag \\
I_{S}(S_1;S_2)\xi = \ & I_S(S_2)(I_S(S_1)\xi) \notag 
\end{align}
Consider, for example, the following program written in $L_1$:
\begin{align*}
& x:= 3; \\
& x:= 5
\end{align*}
After the program is evaluated, the final state stores the value $5$ for $x$:
\begin{align}
I_S(x:=3; x:=5)\xi  = \ & I_S(x:=5)(I_S(x:=3)\xi ) \notag \\
= \ & I_S(x:=5) \xi [ x:=3 ]  \notag \\
= \ & \xi [ x:=5] \notag
\end{align}
Assume now that the language $L_1$ is extended with an $\abort$ operation, resulting in new language $L_2$: 
\begin{align}
S  \defeq \ & \vvar := \expr \ | \notag \\
& S;S \ | \notag \\
& \abort \notag
\end{align}
Intuitively, the interpretation of $\abort$ in a state $\xi$ should return the same state:
\begin{align}
I_{S}(\abort)\xi = \xi \notag
\end{align}
It is desirable that the following program, after its termination (due to $\abort$) should store $3$ as the value of $x$:
\begin{align*}
& x:= 3; \notag \\
& \abort; \notag \\
& x:= 5 \notag
\end{align*}
However, evaluating the program according to the rules defined above, 
results in $x$ having the value $5$:
\begin{align}
I_S(x:=3;\abort; x:=5)\xi  = \ & I_S(x:=5)(I_S(x:=3; \abort)\xi ) \notag \\
= \ & I_S(x:=5)(I_S(\abort)(I_S(x:=3) \xi)) \notag \\
= \ & I_S(x:=5)(I_S(\abort) \xi [ x:=3 ] )  \notag \\
= \ & I_S(x:=5) \xi [  x:=3 ] \notag \\
= \ & \xi [ x:=5] \notag
\end{align}
This can be solved by defining compositional semantics using continuations. Then interpretation $I_S$ is of the type $(S \rightarrow \state \rightarrow (\state \rightarrow \state))$ and the semantic rules are as follows:
\begin{align}
I_{S}(x:=e) \xi \phi = \ & \phi(\xi [ x:=I_{\expr}(e)]) \notag \\
I_{S}(S_1;S_2)\xi \phi = \ &  I_S(S_1)\xi(\lambda s.I_{S}(S_2)s \phi) \notag \\
I_{S}(\abort) \xi \phi = \ &\xi \notag
\end{align}
Evaluation of the program according to continuation-based interpetation rules results in $x$ being assigned the desired value $3$:
\begin{align}
I_{S}(x:=3; \abort; x:=5) \xi \phi  = \ & I_{S}(x:=3) \xi ( \lambda s. I_{S}(\abort) s ( \lambda s'. I_{S}(x:=5) \xi \phi )) \notag \\
= \ & I_{S}(x:=3) \xi (\lambda s.s) \notag \\
= \ & \lambda s.s (\xi [x:=3] )  \notag \\
= \ & \xi [x:=3] \notag
\end{align}
When $\abort$ is absent, continuation-based evaluation of the program  correctly assigns the value $5$ to $x$:
\begin{align}
I_{S}(x:=3; x:=5) \xi \phi = \ & \phi(\xi[x:=3][x:=5]) \notag \\
= \ & \phi (\xi [x:=5]) \notag
\end{align} \qex
\end{example}

%Next chapter proposes an approach that uses continuations in order to implement the influential pragmatic ideas of Stalnaker~\cite{Stalnaker:1978:Assertion} in Montague's settings. This is done by providing two additional arguments to each $\lambda$-term interpreting a natural language proposition. One argument stands for the continuation of the term. Another argument represents a (previously computed) context. Moreover, within the body of the $\lambda$-term, the continuation is applied to the (possibly updated) context (therefore, the continuation is dependent on the context). This is inspired by Stalnaker's idea that each assertion is made in context, is dependent upon the context and updates the context.\footnote{\cite{Heim:1982:The-Semantics-of-Definite-and-Indefinite-Noun-Phrases} and \cite{Kamp:1981:A-Theory-of-Truth-and-Semantic-Representation} also elaborate the work of Stalnaker~\cite{Stalnaker:1978:Assertion}. They do it, however, in a fundamentally different, non-compositional, way. }
